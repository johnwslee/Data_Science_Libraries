{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdd23d3-bde0-4b49-b2a5-6a58c9dd72e3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d9d9eb-ad0a-459d-b804-586e01e11637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from skimage.transform import resize   # Image Processing Library\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc    # Garbage Collector\n",
    "gc.collect()\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "# Pytorch\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torchvision.io import read_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange\n",
    "\n",
    "import PIL\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8b330b-090b-41d7-800c-cdaa6a2ce8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh(x):\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "thresh = np.vectorize(thresh, otypes=[float]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2d3c0-c3dc-4b13-9ee1-f7546e588954",
   "metadata": {},
   "source": [
    "# Unet Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc152309-5d91-45f9-8d9b-af8d852a7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905eec86-db0e-4741-846d-d27b7523499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.ConvTranspose2d(in_channels=mid_channel, \n",
    "                                     out_channels=out_channels, \n",
    "                                     kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNet, self).__init__()\n",
    "        #Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            # torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n",
    "            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=256, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            # torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            # torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "            torch.nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "        \n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2   # Calculate by how much the bypass should be decreased\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))   # Reduces the bypass by padding -c\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        # Decode\n",
    "        # print(x.shape, encode_block1.shape, encode_block2.shape, encode_block3.shape, bottleneck1.shape)\n",
    "        ##print('Decode Block 3')\n",
    "        # print(bottleneck1.shape, encode_block3.shape)\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        # print(decode_block3.shape)\n",
    "        ##print('Decode Block 2')\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        # print(cat_layer2.shape, encode_block2.shape)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        ##print(cat_layer1.shape, encode_block1.shape)\n",
    "        ##print('Final Layer')\n",
    "        # print(cat_layer1.shape, encode_block1.shape)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        ##print(decode_block1.shape)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        # print(final_layer.shape)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46b679b-b58f-428c-832e-70efa2691aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(in_channel=1, out_channel=2)\n",
    "if use_gpu:\n",
    "    unet = unet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55379612-a6f8-4519-bb59-8babd53cddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a0335d-2dcb-4ac1-b217-1921e179f733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.load_state_dict(torch.load('unet_lung.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9297cd6b-108b-49a1-819b-2da9e0a97707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv_encode1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_encode2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_encode3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (conv_decode3): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (conv_decode2): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb1329-403c-4e0b-95c0-1c13d8df83d7",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0909255e-08c3-4179-8a98-e9e571980537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    img_array = ToTensor()(img)[0].unsqueeze(0).unsqueeze(0)\n",
    "    img_array = img_array.to(device)\n",
    "    prediction = unet(img_array)\n",
    "    prediction = prediction.detach().cpu().squeeze().numpy()[1]\n",
    "    prediction = thresh(prediction)\n",
    "    output = (img[:, :, 0]/255 + prediction)/2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0742026b-01fe-436c-a123-d581505c9df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x29de209c400>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(fn=predict, inputs=gr.Image(shape=(128, 128),), outputs=gr.Image())\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d026aad-ab7b-4fac-ae10-d2b0e29fd079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:575]",
   "language": "python",
   "name": "conda-env-575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
