{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb97429-800d-4adf-ac84-221524e8b722",
   "metadata": {},
   "source": [
    "Original Article is from [Medium](https://medium.com/artificial-corner/jupyter-ai-the-ai-extension-for-jupyter-lab-c4c3be5444fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b7ffc-35f9-4463-9b56-ea30cc3f02c6",
   "metadata": {},
   "source": [
    "# Working with Jupyter AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0124af2-0112-42c5-9805-cf9d97acf361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9310f8d-cc7c-4ca8-8232-2da96241c69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"my_openai_api_key_number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f896f6-2f4f-480b-8450-a53af6f74b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `ai21:j1-large`, `ai21:j1-grande`, `ai21:j1-jumbo`, `ai21:j1-grande-instruct`, `ai21:j2-large`, `ai21:j2-grande`, `ai21:j2-jumbo`, `ai21:j2-grande-instruct`, `ai21:j2-jumbo-instruct` |\n",
       "| `anthropic` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `anthropic:claude-v1`, `anthropic:claude-v1.0`, `anthropic:claude-v1.2`, `anthropic:claude-instant-v1`, `anthropic:claude-instant-v1.0` |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | `cohere:medium`, `cohere:xlarge` |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | This provider does not define a list of models. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai:text-davinci-003`, `openai:text-davinci-002`, `openai:text-curie-001`, `openai:text-babbage-001`, `openai:text-ada-001`, `openai:davinci`, `openai:curie`, `openai:babbage`, `openai:ada` |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai-chat:gpt-4`, `openai-chat:gpt-4-0314`, `openai-chat:gpt-4-32k`, `openai-chat:gpt-4-32k-0314`, `openai-chat:gpt-3.5-turbo`, `openai-chat:gpt-3.5-turbo-0301` |\n",
       "| `openai-chat-new` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | `openai-chat-new:gpt-4`, `openai-chat-new:gpt-4-0314`, `openai-chat-new:gpt-4-32k`, `openai-chat-new:gpt-4-32k-0314`, `openai-chat-new:gpt-3.5-turbo`, `openai-chat-new:gpt-3.5-turbo-0301` |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | This provider does not define a list of models. |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:text-davinci-003` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "anthropic\n",
       "Requires environment variable ANTHROPIC_API_KEY (not set)\n",
       "* anthropic:claude-v1\n",
       "* anthropic:claude-v1.0\n",
       "* anthropic:claude-v1.2\n",
       "* anthropic:claude-instant-v1\n",
       "* anthropic:claude-instant-v1.0\n",
       "\n",
       "cohere\n",
       "Requires environment variable COHERE_API_KEY (not set)\n",
       "* cohere:medium\n",
       "* cohere:xlarge\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable HUGGINGFACEHUB_API_TOKEN (not set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "openai\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai:text-davinci-003\n",
       "* openai:text-davinci-002\n",
       "* openai:text-curie-001\n",
       "* openai:text-babbage-001\n",
       "* openai:text-ada-001\n",
       "* openai:davinci\n",
       "* openai:curie\n",
       "* openai:babbage\n",
       "* openai:ada\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-0314\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0314\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "\n",
       "openai-chat-new\n",
       "Requires environment variable OPENAI_API_KEY (set)\n",
       "* openai-chat-new:gpt-4\n",
       "* openai-chat-new:gpt-4-0314\n",
       "* openai-chat-new:gpt-4-32k\n",
       "* openai-chat-new:gpt-4-32k-0314\n",
       "* openai-chat-new:gpt-3.5-turbo\n",
       "* openai-chat-new:gpt-3.5-turbo-0301\n",
       "\n",
       "sagemaker-endpoint\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:text-davinci-003\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdf055-ed44-4685-83ba-cf8cba2a6fff",
   "metadata": {},
   "source": [
    "# Magic Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1f96d-12e0-4810-aba6-b9dfb9b732ae",
   "metadata": {},
   "source": [
    "Let’s generate code using the `%%ai` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45267a1f-f3da-4145-a28e-025180ce0672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## `lcm(a, b)`\n",
       "```python\n",
       "def lcm(a, b):\n",
       "    \"\"\"\n",
       "    Computes the lowest common multiple of two integers.\n",
       "\n",
       "    Parameters:\n",
       "    a (int): First integer.\n",
       "    b (int): Second integer.\n",
       "\n",
       "    Returns:\n",
       "    lcm (int): Lowest common multiple of a and b.\n",
       "    \"\"\"\n",
       "    # Find the maximum of both integers\n",
       "    m = max(a, b)\n",
       "\n",
       "    # Keep incrementing the larger integer until it is divisible by both a and b\n",
       "    while m % a != 0 or m % b != 0:\n",
       "        m += 1\n",
       "\n",
       "    return m\n",
       "```\n",
       "\n",
       "## `test_lcm()`\n",
       "```python\n",
       "def test_lcm():\n",
       "    \"\"\"\n",
       "    Runs 5 test cases of the lcm function and prints the output.\n",
       "    \"\"\"\n",
       "    test_cases = [(4, 6, 12), (10, 15, 30), (7, 9, 63), (16, 20, 80), (21, 28, 84)]\n",
       "\n",
       "    for a, b, expected_lcm in test_cases:\n",
       "        assert lcm(a, b) == expected_lcm\n",
       "        print(f\"lcm({a}, {b}) = {expected_lcm} ✔️\")\n",
       "\n",
       "test_lcm()\n",
       "```\n",
       "\n",
       "## Output\n",
       "```\n",
       "lcm(4, 6) = 12 ✔️\n",
       "lcm(10, 15) = 30 ✔️\n",
       "lcm(7, 9) = 63 ✔️\n",
       "lcm(16, 20) = 80 ✔️\n",
       "lcm(21, 28) = 84 ✔️\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "A function that computes the lowest common multiples of two integers, and\n",
    "a function that runs 5 test cases of the lowest common multiple function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2c7c3-0f15-43ac-8541-68d79eb23517",
   "metadata": {},
   "source": [
    "As you can see, by default, the output of an `%%ai` command will be formatted as markdown by default. You can change the format of the output to code, image, markdown, math, HTML, JSON, and text by using the `-f` argument of the magic command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4510b7f-60b8-4dc8-8496-aed065819c9b",
   "metadata": {},
   "source": [
    "Let’s set the format to code now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840d8ec2-3a49-43c5-8c95-9d6f84e13fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "A function that computes the lowest common multiples of two integers, and\n",
    "a function that runs 5 test cases of the lowest common multiple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5827853-67e8-49ec-96aa-099515384c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcm(a, b):\n",
    "    m = max(a, b)\n",
    "    while m % a != 0 or m % b != 0:\n",
    "        m += 1\n",
    "    return m\n",
    "\n",
    "\n",
    "def test_lcm():\n",
    "    test_cases = [(4, 6, 12), (10, 15, 30), (7, 9, 63), (16, 20, 80), (21, 28, 84)]\n",
    "    for a, b, expected_lcm in test_cases:\n",
    "        assert lcm(a, b) == expected_lcm\n",
    "        print(f\"lcm({a}, {b}) = {expected_lcm} ✔️\")\n",
    "\n",
    "\n",
    "test_lcm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec2e6d0-6bc5-4b6a-b42e-f7f92f0558a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lcm(a, b):\n",
    "    if a > b:\n",
    "        greater = a\n",
    "    else:\n",
    "        greater = b\n",
    "    while True:\n",
    "        if greater % a == 0 and greater % b == 0:\n",
    "            lcm = greater\n",
    "            break\n",
    "        greater += 1\n",
    "    return lcm\n",
    "\n",
    "\n",
    "def test_lcm():\n",
    "    assert lcm(3, 4) == 12\n",
    "    assert lcm(5, 7) == 35\n",
    "    assert lcm(10, 15) == 30\n",
    "    assert lcm(12, 18) == 36\n",
    "    assert lcm(9, 27) == 27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3887b-4410-4d2c-ab7e-325b41421500",
   "metadata": {},
   "source": [
    "You can also generate math formulas in markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e098f7ae-e1e8-46cb-b776-f975e4fdfec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \n",
       "    \\frac{\\partial U}{\\partial t} = \\alpha \\left( \\frac{\\partial^2 U}{\\partial x^2} + \\frac{\\partial^2 U}{\\partial y^2} \\right)\n",
       "$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/latex": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f math\n",
    "Generate the 2D heat equation in Latex surrounded by `$$`. Do not include an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567fcec-8cd2-4843-8355-d94ffba0f75d",
   "metadata": {},
   "source": [
    "# In, Out, and Err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6750635-5727-4242-bbac-d6b7d02439d5",
   "metadata": {},
   "source": [
    "If you want to execute a prompt using code that the kernel knows about, but it’s not in the current cell, you can use the curly brace syntax to include variables and other Python expressions in your prompt.\n",
    "\n",
    "This is especially useful when you want to explain code located elsewhere in a Jupyter notebook. Say I have the code below with its input located to `In[8]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a6acfa-e8e6-4670-9dfb-41aaf022279b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de5234ad-1a65-4cac-ae6f-f9fb8e7fe2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is a loop that iterates over the range of integers from 1 to 8 (inclusive). In each iteration, the value of the current integer is stored in the variable `i` and then the value of `i` is printed to the console. \n",
       "\n",
       "The output of this loop would be:\n",
       "```\n",
       "1\n",
       "2\n",
       "3\n",
       "4\n",
       "5\n",
       "6\n",
       "7\n",
       "8\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Explain the code below:\n",
    "{In[8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515258d8-5d70-4f7f-87ef-1c5f41cb6a00",
   "metadata": {},
   "source": [
    "Besides `In`, other special lists with interpolation syntax are `Out` and `Err` that can be helpful whenever you want to work with the output or error you get."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c91e4d-7da6-4e4e-9593-0f072a36bcc9",
   "metadata": {},
   "source": [
    "Here’s an example of the `Err`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf29aef6-ba77-4e71-b148-a90c83362876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (899903221.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in range(1, 9)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d781e92f-cfaa-43d2-b630-12cd3e27deec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is a `SyntaxError` in Python, which occurs when there is a mistake in the syntax of the code. Specifically, the error is expected `:` after the `for` statement in the line of code.\n",
       "\n",
       "In this case, the mistake is that the `for` loop is not properly constructed because a colon `:` is expected after the range function statement. The interpreter was expecting to read a `:` character at the end of the line where `range` function is being used to indicate the start of the block of code to execute in each iteration.\n",
       "\n",
       "To resolve this issue, a colon `:` should be added at the end of the `for` statement, like this:\n",
       "```\n",
       "for i in range(1, 9):\n",
       "    # do something with i\n",
       "``` \n",
       "This would solve the problem and allow the interpreter to execute the code without errors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "Explain the following Python error:\n",
    "{Err[10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85249c69-e8e0-42ad-a3a1-de7afbc272c2",
   "metadata": {},
   "source": [
    "# Using the chat interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53509c8b-5f96-48fb-8a4c-23af68cac7eb",
   "metadata": {},
   "source": [
    "One cool feature the chat interface has is to generate an entire notebook from a text prompt. You only need to send a message starting with `/generate` like in the example below."
   ]
  },
  {
   "cell_type": "raw",
   "id": "247c9f2f-78c2-4667-8368-53700f669cde",
   "metadata": {},
   "source": [
    "/generate a demo of how to use the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413698d-6378-49ab-b723-01d758b16c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_ai]",
   "language": "python",
   "name": "conda-env-jupyter_ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
